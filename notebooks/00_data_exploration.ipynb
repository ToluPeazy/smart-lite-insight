{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 \u2014 Data Exploration\n",
    "**Smart-Lite Insight: UCI Household Electric Power Consumption**\n",
    "\n",
    "This notebook explores the UCI dataset loaded into our SQLite database. We'll examine:\n",
    "1. Data shape, types, and basic statistics\n",
    "2. Missing data patterns\n",
    "3. Daily and weekly consumption profiles\n",
    "4. Distributions of key metrics\n",
    "5. Correlations between variables\n",
    "6. Identification of natural anomalies for manual labelling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Notebook display settings\n",
    "pd.set_option(\"display.max_columns\", 15)\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 5)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "\n",
    "DB_PATH = \"data/processed/energy.db\"\n",
    "print(f\"Database: {Path(DB_PATH).resolve()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data from SQLite\n",
    "\n",
    "We load only the **UCI real data** (`site_id = 'home-01'`), excluding synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "df = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        timestamp,\n",
    "        global_active_power_kw,\n",
    "        global_reactive_power_kw,\n",
    "        voltage_v,\n",
    "        global_intensity_a,\n",
    "        sub_metering_1_wh,\n",
    "        sub_metering_2_wh,\n",
    "        sub_metering_3_wh\n",
    "    FROM readings\n",
    "    WHERE site_id = 'home-01'\n",
    "    ORDER BY timestamp\n",
    "    \"\"\",\n",
    "    conn,\n",
    "    parse_dates=[\"timestamp\"],\n",
    ")\n",
    "conn.close()\n",
    "\n",
    "df = df.set_index(\"timestamp\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"Duration: {(df.index.max() - df.index.min()).days} days\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Statistics\n",
    "\n",
    "First look at the data \u2014 types, distributions, and obvious issues."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "Look at the `describe()` output above and note:\n",
    "- **Range of values**: Are min/max physically reasonable?\n",
    "- **Mean vs median (50%)**: Large differences suggest skewness.\n",
    "- **Standard deviation**: How variable is each metric?\n",
    "\n",
    "Write your observations below after running the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Missing Data Analysis\n",
    "\n",
    "The UCI dataset documentation states ~1.25% of rows have missing values.\n",
    "Our ingestion pipeline skipped these rows entirely, so we need to check\n",
    "for **temporal gaps** rather than null values."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Check for nulls (should be zero \u2014 we skipped missing rows during ingestion)\n",
    "null_counts = df.isnull().sum()\n",
    "print(\"Null values per column:\")\n",
    "print(null_counts)\n",
    "print(f\"\\nTotal nulls: {null_counts.sum()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Check for temporal gaps (missing timestamps)\n",
    "# The data should have 1-minute intervals\n",
    "time_diffs = df.index.to_series().diff()\n",
    "gap_mask = time_diffs > pd.Timedelta(minutes=1)\n",
    "gaps = time_diffs[gap_mask]\n",
    "\n",
    "print(f\"Total temporal gaps: {len(gaps)}\")\n",
    "print(f\"\\nLargest gaps:\")\n",
    "print(gaps.nlargest(10).to_frame(\"gap_duration\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualise missing data pattern across the full date range\n",
    "# Resample to daily counts \u2014 days with < 1440 rows have missing data\n",
    "daily_counts = df.resample(\"D\").size()\n",
    "expected_per_day = 1440  # 24 * 60\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "ax.bar(daily_counts.index, daily_counts.values, width=1, color=\"steelblue\", alpha=0.7)\n",
    "ax.axhline(y=expected_per_day, color=\"red\", linestyle=\"--\", alpha=0.5, label=f\"Expected ({expected_per_day})\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Readings per day\")\n",
    "ax.set_title(\"Data Completeness: Readings per Day\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Quantify\n",
    "incomplete_days = (daily_counts < expected_per_day).sum()\n",
    "total_days = len(daily_counts)\n",
    "print(f\"Days with missing data: {incomplete_days} / {total_days} ({100*incomplete_days/total_days:.1f}%)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Daily Consumption Patterns\n",
    "\n",
    "How does energy usage vary throughout the day? This is critical for\n",
    "feature engineering later \u2014 hour-of-day will be a key feature."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Average consumption by hour of day\n",
    "hourly = df.groupby(df.index.hour)[\"global_active_power_kw\"].agg([\"mean\", \"std\", \"median\"])\n",
    "hourly.columns = [\"mean_kw\", \"std_kw\", \"median_kw\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(hourly.index, hourly[\"mean_kw\"], \"o-\", color=\"steelblue\", label=\"Mean\")\n",
    "ax.plot(hourly.index, hourly[\"median_kw\"], \"s--\", color=\"coral\", label=\"Median\")\n",
    "ax.fill_between(\n",
    "    hourly.index,\n",
    "    hourly[\"mean_kw\"] - hourly[\"std_kw\"],\n",
    "    hourly[\"mean_kw\"] + hourly[\"std_kw\"],\n",
    "    alpha=0.2,\n",
    "    color=\"steelblue\",\n",
    "    label=\"\u00b11 std\",\n",
    ")\n",
    "ax.set_xlabel(\"Hour of Day\")\n",
    "ax.set_ylabel(\"Global Active Power (kW)\")\n",
    "ax.set_title(\"Average Household Power Consumption by Hour of Day\")\n",
    "ax.set_xticks(range(24))\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Weekday vs Weekend comparison\n",
    "df[\"hour\"] = df.index.hour\n",
    "df[\"is_weekend\"] = df.index.dayofweek >= 5\n",
    "\n",
    "weekday_hourly = df[~df[\"is_weekend\"]].groupby(\"hour\")[\"global_active_power_kw\"].mean()\n",
    "weekend_hourly = df[df[\"is_weekend\"]].groupby(\"hour\")[\"global_active_power_kw\"].mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(weekday_hourly.index, weekday_hourly.values, \"o-\", label=\"Weekday\", color=\"steelblue\")\n",
    "ax.plot(weekend_hourly.index, weekend_hourly.values, \"s-\", label=\"Weekend\", color=\"coral\")\n",
    "ax.set_xlabel(\"Hour of Day\")\n",
    "ax.set_ylabel(\"Mean Global Active Power (kW)\")\n",
    "ax.set_title(\"Weekday vs Weekend Consumption Pattern\")\n",
    "ax.set_xticks(range(24))\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Weekly and Monthly Trends\n",
    "\n",
    "Longer-term patterns \u2014 seasonal variation and weekly cycles."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Weekly average consumption\n",
    "weekly = df[\"global_active_power_kw\"].resample(\"W\").mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "ax.plot(weekly.index, weekly.values, color=\"steelblue\", linewidth=1)\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Mean Active Power (kW)\")\n",
    "ax.set_title(\"Weekly Average Power Consumption Over Time\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Monthly boxplot \u2014 shows seasonal variation + spread\n",
    "df[\"month\"] = df.index.month\n",
    "monthly_data = [df[df[\"month\"] == m][\"global_active_power_kw\"].values for m in range(1, 13)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "bp = ax.boxplot(monthly_data, labels=[\n",
    "    \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n",
    "    \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"\n",
    "], patch_artist=True, showfliers=False)\n",
    "for patch in bp[\"boxes\"]:\n",
    "    patch.set_facecolor(\"steelblue\")\n",
    "    patch.set_alpha(0.6)\n",
    "ax.set_xlabel(\"Month\")\n",
    "ax.set_ylabel(\"Global Active Power (kW)\")\n",
    "ax.set_title(\"Monthly Distribution of Power Consumption (outliers hidden)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Distributions of Key Metrics\n",
    "\n",
    "Understanding the shape of each variable helps choose appropriate\n",
    "models and detect obvious issues."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "columns = [\n",
    "    \"global_active_power_kw\",\n",
    "    \"global_reactive_power_kw\",\n",
    "    \"voltage_v\",\n",
    "    \"global_intensity_a\",\n",
    "    \"sub_metering_1_wh\",\n",
    "    \"sub_metering_2_wh\",\n",
    "    \"sub_metering_3_wh\",\n",
    "]\n",
    "\n",
    "for i, col in enumerate(columns):\n",
    "    axes[i].hist(df[col].dropna(), bins=80, color=\"steelblue\", alpha=0.7, edgecolor=\"white\")\n",
    "    axes[i].set_title(col.replace(\"_\", \" \").title(), fontsize=10)\n",
    "    axes[i].set_ylabel(\"Count\")\n",
    "\n",
    "# Hide unused subplot\n",
    "axes[7].set_visible(False)\n",
    "\n",
    "plt.suptitle(\"Distribution of All Metrics\", fontsize=13, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis\n",
    "\n",
    "How do the variables relate to each other? Strong correlations tell us\n",
    "which features carry redundant information."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "corr = df[columns].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 7))\n",
    "im = ax.imshow(corr, cmap=\"RdBu_r\", vmin=-1, vmax=1)\n",
    "\n",
    "# Labels\n",
    "short_labels = [c.replace(\"global_\", \"\").replace(\"_kw\", \"\").replace(\"_wh\", \"\").replace(\"_v\", \"\").replace(\"_a\", \"\")\n",
    "                for c in columns]\n",
    "ax.set_xticks(range(len(columns)))\n",
    "ax.set_yticks(range(len(columns)))\n",
    "ax.set_xticklabels(short_labels, rotation=45, ha=\"right\", fontsize=9)\n",
    "ax.set_yticklabels(short_labels, fontsize=9)\n",
    "\n",
    "# Annotate\n",
    "for i in range(len(columns)):\n",
    "    for j in range(len(columns)):\n",
    "        ax.text(j, i, f\"{corr.iloc[i, j]:.2f}\", ha=\"center\", va=\"center\", fontsize=8,\n",
    "                color=\"white\" if abs(corr.iloc[i, j]) > 0.5 else \"black\")\n",
    "\n",
    "plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "ax.set_title(\"Correlation Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "After running the correlation matrix, note:\n",
    "- **Active power \u2194 Intensity**: Expected to be very high (P \u2248 V \u00d7 I).\n",
    "- **Sub-meters vs total**: How much of total consumption do the 3 sub-meters capture?\n",
    "- **Voltage**: Typically low correlation with power (supply-side, not demand-side).\n",
    "\n",
    "Document your findings here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sub-Metering Analysis\n",
    "\n",
    "The dataset has 3 sub-meters:\n",
    "- **Sub 1**: Kitchen (dishwasher, oven, microwave)\n",
    "- **Sub 2**: Laundry (washing machine, dryer, fridge, light)\n",
    "- **Sub 3**: Water heater + air conditioning\n",
    "\n",
    "The remainder (total - sub1 - sub2 - sub3) is unmetered consumption."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Calculate unmetered consumption (in Wh per minute)\n",
    "# global_active_power is in kW, sub_meterings are in Wh per minute\n",
    "# Convert: kW * 1000/60 = Wh/minute\n",
    "df[\"total_wh_per_min\"] = df[\"global_active_power_kw\"] * 1000 / 60\n",
    "df[\"unmetered_wh\"] = (\n",
    "    df[\"total_wh_per_min\"]\n",
    "    - df[\"sub_metering_1_wh\"]\n",
    "    - df[\"sub_metering_2_wh\"]\n",
    "    - df[\"sub_metering_3_wh\"]\n",
    ").clip(lower=0)\n",
    "\n",
    "# Average share of each sub-meter\n",
    "shares = {\n",
    "    \"Kitchen (Sub 1)\": df[\"sub_metering_1_wh\"].mean(),\n",
    "    \"Laundry (Sub 2)\": df[\"sub_metering_2_wh\"].mean(),\n",
    "    \"Water/AC (Sub 3)\": df[\"sub_metering_3_wh\"].mean(),\n",
    "    \"Unmetered\": df[\"unmetered_wh\"].mean(),\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "colors = [\"#4e79a7\", \"#f28e2b\", \"#e15759\", \"#76b7b2\"]\n",
    "ax.pie(shares.values(), labels=shares.keys(), autopct=\"%1.1f%%\", colors=colors, startangle=90)\n",
    "ax.set_title(\"Average Energy Consumption Breakdown by Sub-Meter\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for name, val in shares.items():\n",
    "    print(f\"  {name}: {val:.2f} Wh/min\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Identifying Natural Anomalies\n",
    "\n",
    "Before we build ML models, we need to understand what anomalies look like\n",
    "in this data. We'll use simple statistical methods to flag potential anomalies,\n",
    "then manually review them to build a labelled evaluation set.\n",
    "\n",
    "**Approach**: Flag readings where `global_active_power_kw` exceeds the\n",
    "99th percentile or drops to near-zero during normally active hours."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Statistical thresholds\n",
    "p99 = df[\"global_active_power_kw\"].quantile(0.99)\n",
    "p01 = df[\"global_active_power_kw\"].quantile(0.01)\n",
    "print(f\"99th percentile: {p99:.3f} kW\")\n",
    "print(f\" 1st percentile: {p01:.3f} kW\")\n",
    "\n",
    "# Flag anomalies: high spikes\n",
    "high_spikes = df[df[\"global_active_power_kw\"] > p99]\n",
    "print(f\"\\nHigh spike readings (>p99): {len(high_spikes):,}\")\n",
    "\n",
    "# Flag anomalies: near-zero during active hours (8am-10pm)\n",
    "active_hours = df[(df.index.hour >= 8) & (df.index.hour <= 22)]\n",
    "low_dropouts = active_hours[active_hours[\"global_active_power_kw\"] < p01]\n",
    "print(f\"Low dropout readings during active hours (<p01): {len(low_dropouts):,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualise a sample week with anomalies highlighted\n",
    "sample_start = df.index.min() + pd.Timedelta(days=30)\n",
    "sample_end = sample_start + pd.Timedelta(days=7)\n",
    "sample = df.loc[sample_start:sample_end, \"global_active_power_kw\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "ax.plot(sample.index, sample.values, color=\"steelblue\", linewidth=0.5, alpha=0.8)\n",
    "\n",
    "# Overlay spikes\n",
    "spike_mask = sample > p99\n",
    "if spike_mask.any():\n",
    "    ax.scatter(sample.index[spike_mask], sample.values[spike_mask],\n",
    "               color=\"red\", s=15, zorder=5, label=f\"Spikes (>{p99:.1f} kW)\")\n",
    "\n",
    "ax.axhline(y=p99, color=\"red\", linestyle=\"--\", alpha=0.3)\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Global Active Power (kW)\")\n",
    "ax.set_title(f\"Sample Week: {sample_start.date()} to {sample_end.date()} (anomalies in red)\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary & Next Steps\n",
    "\n",
    "### Key Findings\n",
    "*Fill in after running all cells:*\n",
    "1. **Data shape**: ___ rows, ___ columns, spanning ___ to ___\n",
    "2. **Missing data**: ___% of expected readings absent\n",
    "3. **Daily pattern**: Peak consumption at ___am and ___pm\n",
    "4. **Seasonal pattern**: Higher consumption in ___ months\n",
    "5. **Sub-metering**: Unmetered consumption accounts for ___% of total\n",
    "6. **Correlations**: Active power strongly correlates with ___\n",
    "7. **Anomaly candidates**: ___ high spikes, ___ low dropouts identified\n",
    "\n",
    "### Next Steps\n",
    "- **Notebook 01**: Deeper exploration of seasonal patterns and sub-meter behaviour\n",
    "- **Notebook 02**: Feature engineering \u2014 build the feature pipeline\n",
    "- **Manual labelling**: Export anomaly candidates to `data/processed/anomaly_labels.csv`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Drop temporary columns\n",
    "df.drop(columns=[\"hour\", \"is_weekend\", \"total_wh_per_min\", \"unmetered_wh\"],\n",
    "        inplace=True, errors=\"ignore\")\n",
    "print(\"Notebook complete.\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}