{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 \u2014 Feature Engineering\n",
    "**Smart-Lite Insight: Building the Feature Pipeline**\n",
    "\n",
    "This notebook develops and tests the feature engineering pipeline that transforms\n",
    "raw energy readings into ML-ready features. Every feature created here will be\n",
    "extracted into `src/features.py` as a reusable module.\n",
    "\n",
    "Features we'll build:\n",
    "1. **Temporal** \u2014 hour, day of week, month, weekend flag, time-of-use period\n",
    "2. **Lag** \u2014 previous readings at 1, 5, 15, 60 minute offsets\n",
    "3. **Rolling statistics** \u2014 mean, std, min, max over 1h, 6h, 24h windows\n",
    "4. **Rate of change** \u2014 first derivative of power consumption\n",
    "5. **Sub-metering ratios** \u2014 proportion of metered vs unmetered load\n",
    "6. **Cyclical encodings** \u2014 sin/cos transforms for hour and day of week"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 30)\n",
    "pd.set_option(\"display.float_format\", \"{:.4f}\".format)\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 5)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "\n",
    "DB_PATH = \"../data/processed/energy.db\"\n",
    "print(f\"Database: {Path(DB_PATH).resolve()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "conn = sqlite3.connect(DB_PATH)\n",
    "df = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        timestamp,\n",
    "        global_active_power_kw,\n",
    "        global_reactive_power_kw,\n",
    "        voltage_v,\n",
    "        global_intensity_a,\n",
    "        sub_metering_1_wh,\n",
    "        sub_metering_2_wh,\n",
    "        sub_metering_3_wh\n",
    "    FROM readings\n",
    "    WHERE site_id = 'home-01'\n",
    "    ORDER BY timestamp\n",
    "    \"\"\",\n",
    "    conn,\n",
    "    parse_dates=[\"timestamp\"],\n",
    ")\n",
    "conn.close()\n",
    "\n",
    "df = df.set_index(\"timestamp\")\n",
    "print(f\"Loaded {len(df):,} rows\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Temporal Features\n",
    "\n",
    "Time-based features capture the cyclical nature of energy consumption.\n",
    "People use more energy at certain hours, on certain days, and in certain seasons."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def add_temporal_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add time-based features from the timestamp index.\"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    # Basic extractions\n",
    "    out[\"hour\"] = out.index.hour\n",
    "    out[\"day_of_week\"] = out.index.dayofweek  # 0=Monday, 6=Sunday\n",
    "    out[\"month\"] = out.index.month\n",
    "    out[\"is_weekend\"] = (out.index.dayofweek >= 5).astype(int)\n",
    "\n",
    "    # Time-of-use periods (common in energy tariffs)\n",
    "    # Off-peak: 00-06, Mid-peak: 06-09 & 17-21, On-peak: 09-17, Evening: 21-00\n",
    "    conditions = [\n",
    "        (out[\"hour\"] >= 0) & (out[\"hour\"] < 6),\n",
    "        (out[\"hour\"] >= 6) & (out[\"hour\"] < 9),\n",
    "        (out[\"hour\"] >= 9) & (out[\"hour\"] < 17),\n",
    "        (out[\"hour\"] >= 17) & (out[\"hour\"] < 21),\n",
    "        (out[\"hour\"] >= 21),\n",
    "    ]\n",
    "    choices = [\"off_peak\", \"morning_peak\", \"daytime\", \"evening_peak\", \"late_evening\"]\n",
    "    out[\"time_of_use\"] = np.select(conditions, choices, default=\"unknown\")\n",
    "\n",
    "    # Cyclical encodings (so hour 23 is close to hour 0)\n",
    "    out[\"hour_sin\"] = np.sin(2 * np.pi * out[\"hour\"] / 24)\n",
    "    out[\"hour_cos\"] = np.cos(2 * np.pi * out[\"hour\"] / 24)\n",
    "    out[\"dow_sin\"] = np.sin(2 * np.pi * out[\"day_of_week\"] / 7)\n",
    "    out[\"dow_cos\"] = np.cos(2 * np.pi * out[\"day_of_week\"] / 7)\n",
    "    out[\"month_sin\"] = np.sin(2 * np.pi * out[\"month\"] / 12)\n",
    "    out[\"month_cos\"] = np.cos(2 * np.pi * out[\"month\"] / 12)\n",
    "\n",
    "    return out\n",
    "\n",
    "df = add_temporal_features(df)\n",
    "print(f\"Shape after temporal features: {df.shape}\")\n",
    "df[[\"hour\", \"day_of_week\", \"is_weekend\", \"time_of_use\",\n",
    "    \"hour_sin\", \"hour_cos\"]].head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualise cyclical encoding \u2014 hour_sin vs hour_cos should form a circle\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Hour cycle\n",
    "hours = df.groupby(\"hour\")[[\"hour_sin\", \"hour_cos\"]].mean()\n",
    "axes[0].scatter(hours[\"hour_sin\"], hours[\"hour_cos\"], c=hours.index, cmap=\"twilight\", s=80, zorder=3)\n",
    "for h in range(24):\n",
    "    axes[0].annotate(str(h), (hours.loc[h, \"hour_sin\"], hours.loc[h, \"hour_cos\"]),\n",
    "                     fontsize=8, ha=\"center\", va=\"center\")\n",
    "axes[0].set_xlabel(\"hour_sin\")\n",
    "axes[0].set_ylabel(\"hour_cos\")\n",
    "axes[0].set_title(\"Cyclical Hour Encoding\")\n",
    "axes[0].set_aspect(\"equal\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Day of week cycle\n",
    "dows = df.groupby(\"day_of_week\")[[\"dow_sin\", \"dow_cos\"]].mean()\n",
    "day_names = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n",
    "axes[1].scatter(dows[\"dow_sin\"], dows[\"dow_cos\"], c=dows.index, cmap=\"Set2\", s=80, zorder=3)\n",
    "for d in range(7):\n",
    "    axes[1].annotate(day_names[d], (dows.loc[d, \"dow_sin\"], dows.loc[d, \"dow_cos\"]),\n",
    "                     fontsize=9, ha=\"center\", va=\"center\")\n",
    "axes[1].set_xlabel(\"dow_sin\")\n",
    "axes[1].set_ylabel(\"dow_cos\")\n",
    "axes[1].set_title(\"Cyclical Day-of-Week Encoding\")\n",
    "axes[1].set_aspect(\"equal\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Cyclical Encoding?\n",
    "\n",
    "Standard integer encoding (hour=0,1,...,23) tells the model that hour 23 is\n",
    "far from hour 0, when in reality they're adjacent. Sin/cos encoding preserves\n",
    "this circular relationship. The same applies to day-of-week and month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lag Features\n",
    "\n",
    "Lag features capture recent history \u2014 what was the power consumption\n",
    "1, 5, 15, and 60 minutes ago? These are essential for time-series\n",
    "anomaly detection because anomalies are defined relative to recent behaviour."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def add_lag_features(df: pd.DataFrame, target_col: str = \"global_active_power_kw\",\n",
    "                     lags: list[int] = None) -> pd.DataFrame:\n",
    "    \"\"\"Add lagged values of the target column.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with time-series data.\n",
    "        target_col: Column to create lags for.\n",
    "        lags: List of lag offsets in minutes (default: [1, 5, 15, 60]).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with lag columns added.\n",
    "    \"\"\"\n",
    "    if lags is None:\n",
    "        lags = [1, 5, 15, 60]\n",
    "\n",
    "    out = df.copy()\n",
    "    for lag in lags:\n",
    "        out[f\"{target_col}_lag_{lag}m\"] = out[target_col].shift(lag)\n",
    "\n",
    "    return out\n",
    "\n",
    "df = add_lag_features(df)\n",
    "lag_cols = [c for c in df.columns if \"_lag_\" in c]\n",
    "print(f\"Lag features added: {lag_cols}\")\n",
    "df[[\"global_active_power_kw\"] + lag_cols].head(65)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualise: current value vs lag_60m \u2014 should show strong correlation\n",
    "sample = df.iloc[1000:2000]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(sample.index, sample[\"global_active_power_kw\"], label=\"Current\", alpha=0.8)\n",
    "ax.plot(sample.index, sample[\"global_active_power_kw_lag_60m\"], label=\"60min ago\", alpha=0.6)\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Power (kW)\")\n",
    "ax.set_title(\"Current vs 60-Minute Lag \u2014 Autocorrelation Visible\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rolling Statistics\n",
    "\n",
    "Rolling windows capture the local trend and variability. A sudden spike\n",
    "looks different depending on whether the rolling mean is high or low."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def add_rolling_features(df: pd.DataFrame, target_col: str = \"global_active_power_kw\",\n",
    "                         windows: list[int] = None) -> pd.DataFrame:\n",
    "    \"\"\"Add rolling mean, std, min, max for given window sizes.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with time-series data.\n",
    "        target_col: Column to compute rolling stats for.\n",
    "        windows: Window sizes in minutes (default: [60, 360, 1440]).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with rolling statistic columns added.\n",
    "    \"\"\"\n",
    "    if windows is None:\n",
    "        windows = [60, 360, 1440]  # 1h, 6h, 24h\n",
    "\n",
    "    out = df.copy()\n",
    "    for w in windows:\n",
    "        label = f\"{w // 60}h\" if w >= 60 else f\"{w}m\"\n",
    "        rolling = out[target_col].rolling(window=w, min_periods=w // 2)\n",
    "\n",
    "        out[f\"{target_col}_roll_mean_{label}\"] = rolling.mean()\n",
    "        out[f\"{target_col}_roll_std_{label}\"] = rolling.std()\n",
    "        out[f\"{target_col}_roll_min_{label}\"] = rolling.min()\n",
    "        out[f\"{target_col}_roll_max_{label}\"] = rolling.max()\n",
    "\n",
    "    return out\n",
    "\n",
    "df = add_rolling_features(df)\n",
    "roll_cols = [c for c in df.columns if \"_roll_\" in c]\n",
    "print(f\"Rolling features added ({len(roll_cols)}):\")\n",
    "for c in roll_cols:\n",
    "    print(f\"  {c}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualise rolling features for a sample day\n",
    "sample_start = df.index.min() + pd.Timedelta(days=35)\n",
    "sample_end = sample_start + pd.Timedelta(days=3)\n",
    "sample = df.loc[sample_start:sample_end]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "# Top: raw + rolling means\n",
    "axes[0].plot(sample.index, sample[\"global_active_power_kw\"],\n",
    "             alpha=0.4, linewidth=0.5, label=\"Raw (1-min)\", color=\"grey\")\n",
    "axes[0].plot(sample.index, sample[\"global_active_power_kw_roll_mean_1h\"],\n",
    "             label=\"1h mean\", color=\"steelblue\", linewidth=1.5)\n",
    "axes[0].plot(sample.index, sample[\"global_active_power_kw_roll_mean_6h\"],\n",
    "             label=\"6h mean\", color=\"coral\", linewidth=1.5)\n",
    "axes[0].plot(sample.index, sample[\"global_active_power_kw_roll_mean_24h\"],\n",
    "             label=\"24h mean\", color=\"green\", linewidth=1.5)\n",
    "axes[0].set_ylabel(\"Power (kW)\")\n",
    "axes[0].set_title(\"Rolling Means at Different Window Sizes\")\n",
    "axes[0].legend(loc=\"upper right\")\n",
    "\n",
    "# Bottom: rolling std (volatility)\n",
    "axes[1].plot(sample.index, sample[\"global_active_power_kw_roll_std_1h\"],\n",
    "             label=\"1h std\", color=\"steelblue\", linewidth=1.5)\n",
    "axes[1].plot(sample.index, sample[\"global_active_power_kw_roll_std_6h\"],\n",
    "             label=\"6h std\", color=\"coral\", linewidth=1.5)\n",
    "axes[1].set_ylabel(\"Std Dev (kW)\")\n",
    "axes[1].set_title(\"Rolling Volatility \u2014 High Std = Unstable Consumption\")\n",
    "axes[1].legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Rate of Change\n",
    "\n",
    "The first derivative of power consumption \u2014 how fast is usage changing?\n",
    "Sudden large changes are often anomalous."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def add_rate_of_change(df: pd.DataFrame, target_col: str = \"global_active_power_kw\") -> pd.DataFrame:\n",
    "    \"\"\"Add rate-of-change (first difference) features.\"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    # Absolute change per minute\n",
    "    out[f\"{target_col}_diff_1m\"] = out[target_col].diff()\n",
    "\n",
    "    # Absolute change per 5 minutes\n",
    "    out[f\"{target_col}_diff_5m\"] = out[target_col].diff(5)\n",
    "\n",
    "    # Percentage change (handle division by zero)\n",
    "    prev = out[target_col].shift(1)\n",
    "    out[f\"{target_col}_pct_change_1m\"] = (\n",
    "        out[target_col].diff() / prev.replace(0, np.nan)\n",
    "    )\n",
    "\n",
    "    return out\n",
    "\n",
    "df = add_rate_of_change(df)\n",
    "diff_cols = [c for c in df.columns if \"_diff_\" in c or \"_pct_change_\" in c]\n",
    "print(f\"Rate-of-change features: {diff_cols}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Distribution of 1-minute changes \u2014 should be centered near 0 with fat tails\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(df[\"global_active_power_kw_diff_1m\"].dropna(), bins=200,\n",
    "             color=\"steelblue\", alpha=0.7, edgecolor=\"white\")\n",
    "axes[0].set_xlabel(\"Change in Power (kW/min)\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[0].set_title(\"Distribution of 1-Minute Power Changes\")\n",
    "axes[0].set_xlim(-5, 5)  # Zoom to main distribution\n",
    "\n",
    "# Q-Q style: sorted absolute changes \u2014 tail behaviour\n",
    "abs_changes = df[\"global_active_power_kw_diff_1m\"].dropna().abs().sort_values()\n",
    "axes[1].plot(abs_changes.values, linewidth=0.5, color=\"steelblue\")\n",
    "axes[1].axhline(y=abs_changes.quantile(0.99), color=\"red\", linestyle=\"--\",\n",
    "                label=f\"99th pctl: {abs_changes.quantile(0.99):.2f} kW\")\n",
    "axes[1].set_xlabel(\"Rank\")\n",
    "axes[1].set_ylabel(\"|Change| (kW/min)\")\n",
    "axes[1].set_title(\"Sorted Absolute Changes \u2014 Tail Shows Anomalous Jumps\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sub-Metering Ratios\n",
    "\n",
    "The proportion of energy captured by each sub-meter tells us about\n",
    "the type of consumption happening at any given time."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def add_submetering_ratios(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add sub-metering ratio features.\"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    # Total sub-metered (Wh/min)\n",
    "    out[\"sub_total_wh\"] = (\n",
    "        out[\"sub_metering_1_wh\"] + out[\"sub_metering_2_wh\"] + out[\"sub_metering_3_wh\"]\n",
    "    )\n",
    "\n",
    "    # Total consumption in Wh/min (from kW)\n",
    "    out[\"total_wh_per_min\"] = out[\"global_active_power_kw\"] * 1000 / 60\n",
    "\n",
    "    # Ratio of metered to total (0-1, can exceed 1 due to measurement noise)\n",
    "    out[\"metered_ratio\"] = (\n",
    "        out[\"sub_total_wh\"] / out[\"total_wh_per_min\"].replace(0, np.nan)\n",
    "    ).clip(0, 1.5)\n",
    "\n",
    "    # Individual sub-meter shares\n",
    "    for i in [1, 2, 3]:\n",
    "        out[f\"sub_{i}_share\"] = (\n",
    "            out[f\"sub_metering_{i}_wh\"] / out[\"sub_total_wh\"].replace(0, np.nan)\n",
    "        ).fillna(0)\n",
    "\n",
    "    return out\n",
    "\n",
    "df = add_submetering_ratios(df)\n",
    "ratio_cols = [\"metered_ratio\", \"sub_1_share\", \"sub_2_share\", \"sub_3_share\"]\n",
    "print(\"Sub-metering ratio statistics:\")\n",
    "df[ratio_cols].describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Complete Feature Set Summary\n",
    "\n",
    "Let's review every feature we've created and check for issues."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Full feature list\n",
    "original_cols = [\n",
    "    \"global_active_power_kw\", \"global_reactive_power_kw\", \"voltage_v\",\n",
    "    \"global_intensity_a\", \"sub_metering_1_wh\", \"sub_metering_2_wh\", \"sub_metering_3_wh\"\n",
    "]\n",
    "engineered_cols = [c for c in df.columns if c not in original_cols]\n",
    "\n",
    "print(f\"Original features:    {len(original_cols)}\")\n",
    "print(f\"Engineered features:  {len(engineered_cols)}\")\n",
    "print(f\"Total features:       {len(df.columns)}\")\n",
    "print(f\"\\nRows before dropping NaN: {len(df):,}\")\n",
    "\n",
    "# Count NaNs per feature (from lags and rolling windows)\n",
    "nan_counts = df[engineered_cols].isnull().sum()\n",
    "nan_pct = (nan_counts / len(df) * 100).round(2)\n",
    "nan_summary = pd.DataFrame({\"nulls\": nan_counts, \"pct\": nan_pct})\n",
    "print(f\"\\nFeatures with NaN (from window warmup):\")\n",
    "print(nan_summary[nan_summary[\"nulls\"] > 0].sort_values(\"nulls\", ascending=False))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Drop rows with NaN (caused by lag/rolling window warmup)\n",
    "df_clean = df.dropna()\n",
    "print(f\"Rows after dropping NaN: {len(df_clean):,}\")\n",
    "print(f\"Rows dropped: {len(df) - len(df_clean):,} ({100*(len(df)-len(df_clean))/len(df):.2f}%)\")\n",
    "print(f\"\\nFinal feature matrix shape: {df_clean.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Correlation Check\n",
    "\n",
    "We need to verify that our engineered features actually carry useful\n",
    "information and aren't perfectly redundant."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Correlation of key engineered features with target\n",
    "target = \"global_active_power_kw\"\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "correlations = df_clean[numeric_cols].corrwith(df_clean[target]).abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 20 features by absolute correlation with active power:\\n\")\n",
    "print(correlations.head(20).to_frame(\"abs_correlation\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Check for highly correlated feature pairs (potential redundancy)\n",
    "corr_matrix = df_clean[numeric_cols].corr().abs()\n",
    "\n",
    "# Get upper triangle pairs with correlation > 0.95\n",
    "high_corr_pairs = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i + 1, len(corr_matrix.columns)):\n",
    "        if corr_matrix.iloc[i, j] > 0.95:\n",
    "            high_corr_pairs.append({\n",
    "                \"feature_1\": corr_matrix.columns[i],\n",
    "                \"feature_2\": corr_matrix.columns[j],\n",
    "                \"correlation\": corr_matrix.iloc[i, j],\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    pairs_df = pd.DataFrame(high_corr_pairs).sort_values(\"correlation\", ascending=False)\n",
    "    print(f\"Highly correlated pairs (>0.95) \u2014 consider dropping one of each:\\n\")\n",
    "    print(pairs_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"No feature pairs with correlation > 0.95\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary & Next Steps\n",
    "\n",
    "### Feature Categories Created\n",
    "\n",
    "| Category | Count | Examples |\n",
    "|----------|-------|---------|\n",
    "| Temporal | ~12 | hour, day_of_week, is_weekend, hour_sin/cos, time_of_use |\n",
    "| Lag | 4 | 1m, 5m, 15m, 60m lags of active power |\n",
    "| Rolling | 12 | mean/std/min/max over 1h, 6h, 24h windows |\n",
    "| Rate of change | 3 | 1m diff, 5m diff, % change |\n",
    "| Sub-metering | 4 | metered_ratio, sub_1/2/3 share |\n",
    "| **Total engineered** | **~35** | |\n",
    "\n",
    "### Key Observations\n",
    "*Fill in after running:*\n",
    "1. Most correlated engineered feature with active power: ___\n",
    "2. Features to consider dropping (redundancy): ___\n",
    "3. NaN rows dropped due to window warmup: ___\n",
    "\n",
    "### Next Steps\n",
    "- Extract all feature functions into `src/features.py`\n",
    "- Write unit tests in `tests/test_features.py`\n",
    "- Use this feature matrix for anomaly detection in Notebook 03"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Feature engineering notebook complete.\")\n",
    "print(f\"Final shape: {df_clean.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}